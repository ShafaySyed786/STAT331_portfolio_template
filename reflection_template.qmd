---
title: "STAT 331 Portfolio"
author: "Shafay Syed"
embed-resources: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
  warning: false
  message: false
format:
  html:
    toc: true
    toc-depth: 3
    toc-location: left
    embed-resources: true
    code-fold: true
    code-tools: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A-.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from Lab or Challenge assignments where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv` Example 1

```{r}
#| label: wd-1-csv-1
# Lab 3 Question 2
teacher_evals <- read_csv(here("Week3", "teacher_evals.csv"), show_col_types = FALSE)
```

-   csv Example 2

```{r}
#| label: wd-1-csv-2
# Lab 7 Setup
fish <- read_csv(here("Week7", "data", "BlackfootFish.csv"), show_col_types = FALSE)
```

-   xlsx

```{r}
#| label: wd-1-xlsx
# Check-in 2.4 Question 5
agesxl <- read_xlsx (path = here::here("Week 2", "Check-ins", "Ages_Data", "ages.xlsx"), sheet = "ages")
```

**WD-2: I can select necessary columns from a dataset.**

-   Example selecting specified columns

```{r}
#| label: wd-2-ex-1
# Lab 3 Question 5
teacher_evals_clean <- teacher_evals |>
  rename(sex = gender) |>
  filter(no_participants >= 10) |>
  mutate(
    across(c(course_id, teacher_id), as.character),
    across(c(question_no, seniority), as.integer),
    academic_degree = as.factor(academic_degree),
    sex             = as.factor(sex)
    ) |>
  select(
    course_id, teacher_id, question_no, no_participants, resp_share,
    SET_score_avg, percent_failed_cur, academic_degree, seniority, sex
  )
```

-   Example removing specified columns

```{r}
# Lab 3 Question 8
#| label: wd-2-ex-2
#| label: uncovering-missing-values
tc_na <- teacher_evals_clean |>
# modified to use named args
  filter(if_any(
      .cols = -c(teacher_id, course_id, question_no),
      .fns  = is.na
    )) |>
  distinct(teacher_id, course_id)

tc_na

teacher_evals_clean |>
  filter(teacher_id == tc_na$teacher_id, course_id == tc_na$course_id) |>
  # named args
  summarise(across(
      .cols = -c(teacher_id, course_id, question_no),
      .fns  = ~ any(is.na(.))
    )) |>
  pivot_longer(
    cols      = everything(),
    names_to  = "variable",
    values_to = "has_na"
  ) |>
  filter(has_na)
```

-   Example selecting columns based on logical values (e.g., `starts_with()`, `ends_with()`, `contains()`, `where()`)

```{r}
#| label: wd-2-ex-3
# Lab 4 Question 7
ca_childcare |>
  select(study_year, census_region, mc_infant, mc_toddler, mc_preschool) |>
  pivot_longer(
  cols = starts_with("mc_"),
  names_to = "age",
  names_prefix = "mc_",
  values_to = "weekly_price",
  values_drop_na = TRUE
  ) |>
  mutate(
  age = fct_recode(factor(age),
  "Infant" = "infant",
  "Toddler" = "toddler",
  "Preschool" = "preschool"),
  age = fct_relevel(age, "Infant", "Toddler", "Preschool"),
census_region = fct_reorder(
  census_region,
  if_else(age == "Infant" & study_year == 2018, weekly_price, NA_real_),
  .fun = ~ max(., na.rm = TRUE),
  .desc = TRUE
  )
) # continues after here, but not relavent for this wd
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
# Lab 4 Question 5
income_region_2008_2018 <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(census_region, study_year) |>
  summarise(median_mhi_2018 = median(mhi_2018, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(
    names_from = study_year,
    values_from = median_mhi_2018
  ) |>
  rename(region = census_region) |>
  arrange(desc(`2018`))

income_region_2008_2018
```

-   Numeric Example 2

```{r}
#| label: question-1-high-low
# Lab 3 Question 10
q10 <- teacher_evals_clean |>
  filter(question_no == 901) |>
  group_by(teacher_id) |>
  summarise(
  n_courses = n_distinct(course_id),
  avg_q1 = mean(SET_score_avg, na.rm = TRUE),
  .groups = "drop"
  ) |>
  filter(n_courses >= 5)

bind_rows(
  q10 |> slice_max(avg_q1, n = 1, with_ties = TRUE) |> mutate(which = "highest"),
  q10 |> slice_min(avg_q1, n = 1, with_ties = TRUE) |> mutate(which = "lowest")
)
```

-   Character Example 1

```{r}
# Lab 5 Initial Investigation Using Assignment Hints
crime_clue <- crime_scene_report |>
  mutate(date = ymd(date)) |>
  filter(city == "SQL City", type == "murder", date == murder_date) |>
  distinct(description)
```

-   Character Example 2 (example must use functions from **stringr**)

```{r}
#| label: wd-3-string
# Lab 5 Initial Investigation Using Assignment Hints
witness2 <- person |>
  filter(address_street_name == "Franklin Ave",
         # name starts with Annabel
         str_detect(name, regex("^Annabel", ignore_case = TRUE))) |>
  left_join(interview, by = c("id" = "person_id"))
```

-   Date (example must use functions from **lubridate**)

```{r}
#| label: wd-3-date
# Lab 5 Initial Investigation Using Assignment Hints
crime_clue <- crime_scene_report |>
  mutate(date = ymd(date)) |>
  # We were told this through the text above which tells us SQL City, date, and murder details
  filter(city == "SQL City", type == "murder", date == ymd("2018-01-15")) |>
  pull(description) |>
  unique()
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   Numeric Example 1

```{r}
# Challenge 4 Summary Table
summary_table <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(census_region, study_year) |>
  summarise(
    center = median(mc_infant, na.rm = TRUE),
    family = median(mfcc_infant, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(names_from = study_year, values_from = c(center, family), names_sep = "_") |>
  mutate(
    region = census_region,
    `Center 2008` = center_2008,
    `Family 2008` = family_2008,
    `Center 2018` = center_2018,
    `Family 2018` = family_2018,
    `Gap 2018 (Center−Family)` = center_2018 - family_2018
  ) |>
  select(region, `Center 2008`, `Family 2008`, `Center 2018`, `Family 2018`, `Gap 2018 (Center−Family)`) |>
  arrange(desc(`Center 2018`)) |>
  mutate(across(where(is.numeric), ~ round(.)))
kable(summary_table, caption = "Median weekly infant prices (USD) by region and setting, 2008 vs 2018")
```

-   Numeric Example 2

```{r}
#| label: transform-data-to-have-correct-units
# Challenge 7 Question 1
fish <- fish |>
  mutate(length_cm = length / 10)
```

-   Factor Example 1 (renaming levels)

```{r}
#| label: wd-4-factor-ex-1
# Lab 4 Question 7
mutate(
  age = fct_recode(factor(age),
  "Infant" = "infant",
  "Toddler" = "toddler",
  "Preschool" = "preschool"),
  age = fct_relevel(age, "Infant", "Toddler", "Preschool"),
census_region = fct_reorder(
  census_region,
  if_else(age == "Infant" & study_year == 2018, weekly_price, NA_real_),
  .fun = ~ max(., na.rm = TRUE),
  .desc = TRUE
  )
)
```

-   Factor Example 1 (reordering levels)

```{r}
# Lab 9 Question 6
mutate(
    variable = fct_relevel(variable, "Seniority","Sex","Academic Degree"),
    level_order = case_when(
# https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/match
      variable == "Academic Degree" ~ match(level, c("No Degree","Masters","Doctorate","Tenured Professor")),
      variable == "Seniority"       ~ match(level, c("Junior","Senior")),
      variable == "Sex"             ~ match(level, c("Female","Male")),
      TRUE ~ NA_integer_
    )
  )
```

-   Character (example must use functions from **stringr**)

```{r}
#| label: wd-4-string
# Lab 9 Question 5
mutate(
    sen_level = case_when(
      seniority <= 4 ~ "Junior",
      seniority <= 8 ~ "Senior",
      seniority >  8 ~ "Very Senior",
      TRUE ~ NA_character_
    ),
    academic_degree = case_when(
      str_to_lower(academic_degree) %in% c("phd","doctorate","doctoral") ~ "Doctorate",
      str_to_lower(academic_degree) %in% c("masters","master","ma","ms")  ~ "Masters",
      str_detect(str_to_lower(academic_degree), "no")                      ~ "No Degree",
      str_detect(str_to_lower(academic_degree), "tenur")                   ~ "Tenured Professor",
      TRUE ~ academic_degree
    ),
    sex = str_to_title(sex)
  )
```

-   Date (example must use functions from **lubridate**)

```{r}
# Lab 5 Initial Investigation Using Assignment Hints
#| label: wd-4-date
crime_clue <- crime_scene_report |>
  mutate(date = ymd(date)) |>
  # We were told this through the text above which tells us SQL City, date, and murder details
  filter(city == "SQL City", type == "murder", date == ymd("2018-01-15")) |>
  pull(description) |>
  unique()
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()` Example 1

```{r}
#| label: wd-5-left-ex-1
# Lab 4 Question 3
#| label: add-tax-information
ca_childcare <- ca_childcare |>
  left_join(
    tax_rev,
    by = c("county_name" = "entity_name", "study_year" = "year")
  )
```

-   `right_join()` Example 1

```{r}
#| label: wd-5-right
# Lab 5 Initial Investigation Using Assignment Hints
# changed for purposes of portfolio
# Original:
witness1 <- person |>
  rename(person_id = id) |>
  filter(address_street_name == "Northwestern Dr") |>
  slice_max(address_number, n = 1) |>
  left_join(interview, by = "person_id")
# Modified:
witness1_right <- interview |>
  right_join(
    person |>
      rename(person_id = id) |>
      filter(address_street_name == "Northwestern Dr") |>
      slice_max(address_number, n = 1),
    by = "person_id"
)
```

-   Left or Right Join Example 2

```{r}
#| label: wd-5-right-or-left
# Lab 5 Final Candidate Investigation
# The original unmodified part from right_join() Example 1
witness1 <- person |>
  rename(person_id = id) |>
  filter(address_street_name == "Northwestern Dr") |>
  slice_max(address_number, n = 1) |>
  left_join(interview, by = "person_id")
```

-   `inner_join()` Example 1

```{r}
#| label: wd-5-inner-ex-1
# Lab 5 Gym and Plate Investigation
gym_on_jan9 <- get_fit_now_check_in |>
  filter(check_in_date == 20180109) |>
  inner_join(gym_candidates, by = c("membership_id" = "id")) |>
  distinct(person_id)
```

-   inner_join() Example 2

```{r}
#| label: wd-5-inner-ex-2
# Lab 5 Car and Physical description investigation of Mastermind
candidates_attr <- person |>
  inner_join(drivers_license2, by = "license_id") |>
  filter(
    hair_color == "red",
    between(height, 65, 67),
    car_make  == "Tesla",
    car_model == "Model S"
  ) |>
  select(id, name, license_id, hair_color, height, car_make, car_model) |>
  distinct()
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r}
#| label: wd-6-semi
# Original Lab 5 Code:
gym_on_jan9 <- get_fit_now_check_in |>
  filter(check_in_date == 20180109) |>
  inner_join(gym_candidates, by = c("membership_id" = "id")) |>
  distinct(person_id)
# Modified Lab 5 Code:
gym_on_jan9 <- gym_candidates |>
  semi_join(
    get_fit_now_check_in |>
      filter(check_in_date == 20180109),
    by = c("id" = "membership_id")
  ) |>
  distinct(person_id)
```

-   `anti_join()`

```{r}
#| label: wd-6-anti
# Original Lab 5 Code:
concert_visitors <- facebook_event_checkin |>
  filter(event_name == "SQL Symphony Concert",
                date >= 20171201, date <= 20171231) |>
  count(person_id, name = "visits") |>
  filter(visits >= 3)

final_candidates <- candidates_attr |>
  rename(person_id = id) |>
  inner_join(concert_visitors, by = "person_id")
# Modified Lab 5 Code to show visitors who did NOT visit the concert:
concert_visitors <- facebook_event_checkin |>
  filter(event_name == "SQL Symphony Concert",
         date >= 20171201, date <= 20171231) |>
  count(person_id, name = "visits") |>
  filter(visits >= 3)

non_concert_candidates <- candidates_attr |>
  rename(person_id = id) |>
  anti_join(concert_visitors, by = "person_id")
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r}
#| label: wd-7-long
# Lab 4 Question 7
ca_childcare |>
  select(study_year, census_region, mc_infant, mc_toddler, mc_preschool) |>
  pivot_longer(
  cols = starts_with("mc_"),
  names_to = "age",
  names_prefix = "mc_",
  values_to = "weekly_price",
  values_drop_na = TRUE
  )
```

-   `pivot_wider()`

```{r}
#| label: wd-7-wide
# Lab 4 Question 5
#| label: median-income-by-region-over-time
income_region_2008_2018 <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(census_region, study_year) |>
  summarise(
    median_mhi = median(mhi_2018, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(
    names_from  = study_year,
    values_from = median_mhi,
    names_glue  = "median_mhi_{study_year}"
  ) |>
  rename(region = census_region) |>
  arrange(desc(median_mhi_2018))

income_region_2008_2018
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

The following assignments satisfy the above criteria:

-   Lab 2
-   Challenge 2
-   Challenge 3
-   Lab 4
-   Lab 5

**R-2: I can write well documented and tidy code.**

-   Example of **ggplot2** plotting

```{r}
# Lab 4 Question 7
#| label: r-2-1
#| label: recreate-plot
#| fig-width: 12
#| fig-height: 4.5
pal10 <- colorRampPalette(RColorBrewer::brewer.pal(8, "Set2"))(10)

ca_childcare |>
  select(study_year, census_region, mc_infant, mc_toddler, mc_preschool) |>
  # Change wide multiple age price columns into long
  pivot_longer(
  cols = starts_with("mc_"),
  names_to = "age",
  names_prefix = "mc_",
  values_to = "weekly_price",
  values_drop_na = TRUE
  ) |>
  mutate(
  # Rename age categories and set display order
  age = fct_recode(factor(age),
  "Infant" = "infant",
  "Toddler" = "toddler",
  "Preschool" = "preschool"),
  # Reorder regions based on 2018 infant prices
  age = fct_relevel(age, "Infant", "Toddler", "Preschool"),
census_region = fct_reorder(
  census_region,
  if_else(age == "Infant" & study_year == 2018, weekly_price, NA_real_),
  .fun = ~ max(., na.rm = TRUE),
  .desc = TRUE
  )
) |>
  # price over time which is colored by region
  ggplot(aes(study_year, weekly_price, color = census_region)) +
  geom_point(alpha = 0.6, size = 1.7) +
  # trend lines with confidence bands
  geom_smooth(method = "loess", formula = y ~ x, se = TRUE, linewidth = 0.8) +
  facet_wrap(~ age, nrow = 1) +
  scale_x_continuous(breaks = seq(2008, 2018, 2), limits = c(2008, 2018)) +
  scale_y_continuous(breaks = seq(100, 500, 50),
  limits = c(100, 520),
  labels = scales::label_dollar()) +
  scale_color_manual(values = pal10, name = "California Region") +
  labs(
  title = "Weekly Median Price for Center-Based Childcare ($)",
  x = "Study Year",
  y = "Weekly Median Price ($)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
  legend.position = "right",
  aspect.ratio = 1,
  panel.grid.minor = element_blank()
)

```

-   Example of **dplyr** pipeline

```{r}
# Challenge 3 Part 1
#| label: r-2-2
# Keep only rows for question 903
teacher_evals_compare <- teacher_evals |>
  filter(question_no == 903) |>
  mutate(
    SET_level = if_else(SET_score_avg >= 4, "excellent", "standard"),
    # Categorize instructor seniority into groups
    sen_level = case_when(
      seniority <= 4 ~ "junior",
      seniority <= 8 ~ "senior",
      TRUE           ~ "very senior"
    )
  ) |>
  select(course_id, SET_level, sen_level)

```

-   Example of function formatting

```{r}
#| label: r-2-3
# Challenge 4 Summary Table
# Building a summary table of median infant prices by region and year.
summary_table <- ca_childcare |>
  # Keeping only the two study years of interest
  filter(study_year %in% c(2008, 2018)) |>
  group_by(census_region, study_year) |>
  summarise(
    center = median(mc_infant, na.rm = TRUE),
    family = median(mfcc_infant, na.rm = TRUE),
    .groups = "drop"
  ) |>
  # Go from long, year as rows, to wide using year as columns.
  pivot_wider(
    names_from  = study_year,
    values_from = c(center, family),
    names_sep   = "_"
  ) |>
  mutate(
    region = census_region,
    `Median center price, 2008 (USD/week)`  = center_2008,
    `Median family price, 2008 (USD/week)`  = family_2008,
    `Median center price, 2018 (USD/week)`  = center_2018,
    `Median family price, 2018 (USD/week)`  = family_2018,
    `Gap in 2018 (center − family, USD/week)` = center_2018 - family_2018
  ) |>
  select(
  region,
    `Median center price, 2008 (USD/week)`,
    `Median family price, 2008 (USD/week)`,
    `Median center price, 2018 (USD/week)`,
    `Median family price, 2018 (USD/week)`,
    `Gap in 2018 (center − family, USD/week)`
  ) |>
  arrange(desc(`Center 2018`)) |>
  mutate(
    across(
      where(is.numeric),
      ~ round(.)
    )
  )

# Formatted function call with multiple arguments.
kable(
  summary_table,
  caption   = "Median weekly infant prices (USD) by region and setting, 2008 vs 2018",
  align     = "lrrrrr",
  booktabs  = TRUE
)

```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example (any context)

```{r}
# Lab 4 Question 5
# This example is robust because it doesn't depend on or assume a fixed set of regions.
#| label: r-3-example
#| label: median-income-by-region-over-time
income_region_2008_2018 <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(census_region, study_year) |>
  summarise(median_mhi_2018 = median(mhi_2018, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(
    names_from = study_year,
    values_from = median_mhi_2018
  ) |>
  rename(region = census_region) |>
  arrange(desc(`2018`))

```

-   Example (function stops)

```{r}
#| label: r-3-function-stops
# Lab 8 Question 1
rescale_01 <- function(x) {
  if (!is.numeric(x)) {
    stop("`x` must be numeric.")
  }
  if (length(x) <= 1) {
    stop("`x` must have length greater than 1.")
  }
  r <- range(x, na.rm = TRUE)
  (x - r[1]) / (r[2] - r[1])
}

rescale_column <- function(data, cols) {
  mutate(data, across({{ cols }}, rescale_01))
}
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   At least two numeric variables

```{r}
# Lab 4 Question 8
#| label: dvs-1-num
#| label: scatterplot-median-income-vs-childcare-cost
ca_childcare |>
  filter(!is.na(mhi_2018), !is.na(mc_infant)) |>
  mutate(
    census_region = fct_reorder(census_region, mc_infant, .fun = median, .desc = TRUE)
  ) |>
  ggplot(aes(x = mhi_2018, y = mc_infant, color = census_region)) +
  geom_point(alpha = 0.6, size = 1.5) +
  geom_smooth(aes(group = 1), method = "lm", se = FALSE) +
  scale_x_continuous(labels = scales::dollar_format(accuracy = 1)) +
  scale_y_continuous(labels = scales::dollar_format(accuracy = 1)) +
  labs(
    x = "Median household income (2018 dollars)",
    y = "Weekly price: center-based infant care ($)",
    color = "California Region",
    title = "Median Household Income vs. Infant Center-Based Childcare Prices (CA)"
  ) +
  theme_minimal(base_size = 12) +
  theme(aspect.ratio = 1)
```

-   At least one numeric variable and one categorical variable

```{r}
# Challenge 2
#| label: dvs-2-num-cat
#| label: medium-option-colors
#| echo: true
#| message: false
#| warning: false

p_base <- ggplot(
  plot_df,
  aes(x = species, y = weight, fill = sex)
) +
  geom_boxplot(
    outlier.shape = NA,
    position = position_dodge2(width = 0.8, preserve = "single")
  ) +
  geom_jitter(
    aes(color = sex),
    alpha = 0.35,
    position = position_jitterdodge(
      jitter.width = 0.15,
      jitter.height = 0,
      dodge.width = 0.8
    )
  ) +
  labs(
    title = "Rodent Weight by Species and Sex",
    x = "Species",
    y = "Weight (g)",
    fill = "Sex",
    color = "Sex"
  ) +
  # Changed to make easier to read instead of tilting head.
  coord_flip()
  theme_minimal()

sex_cols <- c(F = "steelblue", M = "orange3")
p_manual <- p_base +
  scale_fill_manual(values = sex_cols) +
  scale_color_manual(values = sex_cols, guide = "none")
p_manual

p_pkg <- p_base +
  # Source: https://ggplot2.tidyverse.org/reference/scale_viridis.html
  scale_fill_viridis_d(option = "C") +
  scale_color_viridis_d(option = "C", guide = "none")
p_pkg

```

-   At least two categorical variables

```{r}
# Challenge 3 Part 2
#| label: dvs-2-cat
#| label: recreate-plot
ggplot(teacher_evals_compare, aes(x = sen_level, fill = SET_level)) +
  geom_bar(stat = "count", position = "fill", width = 0.9) +
  # Updated percent_format to label_percent.
  scale_y_continuous(labels = scales::label_percent(accuracy = 1), expand = c(0, 0)) +
  scale_fill_manual(
    name = "Evaluation Rating",
    values = c(excellent = "#B39DDB", standard = "#B48A54")
  ) +
  labs(
    title = "Evaluation of Teachers' Use of Activities",
    x = "Years of Experience", y = NULL
  ) +
  theme_minimal(base_size = 16) +
  theme(legend.position = "top", panel.grid.minor = element_blank())
```

-   Dates (time series plot)

```{r}
# Challenge 7 Question 5
#| label: dvs-2-date
#| label: condition-indices-over-time
ci_by_year_species <- fish |>
  mutate(ci = condition_index(weight, length_cm)) |>
  drop_na(ci, year, species) |>
  group_by(year, species) |>
  summarise(median_ci = median(ci), n = n(), .groups = "drop") |>
  ungroup() |>
  mutate(species = fct_reorder(species, median_ci, .fun = median))

ci_by_year_species |>
  ggplot(aes(x = year, y = median_ci, color = species)) +
  geom_line() +
  geom_point(aes(size = n)) +
  labs(
    title = "Fish Condition Index Over Time by Species",
    x = "Year",
    y = "Median condition index",
    color = "Species",
    size  = "n fish"
  ) +
  theme_minimal()
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   I can modify my plot theme to be more readable

```{r}
# Lab 4 Question 7
#| label: dvs-2-ex-1
#| label: recreate-plot
#| fig-width: 12
#| fig-height: 4.5

pal10 <- colorRampPalette(RColorBrewer::brewer.pal(8, "Set2"))(10)

ca_childcare |>
  select(study_year, census_region, mc_infant, mc_toddler, mc_preschool) |>
  pivot_longer(
  cols = starts_with("mc_"),
  names_to = "age",
  names_prefix = "mc_",
  values_to = "weekly_price",
  values_drop_na = TRUE
  ) |>
  mutate(
  age = fct_recode(factor(age),
  "Infant" = "infant",
  "Toddler" = "toddler",
  "Preschool" = "preschool"),
  age = fct_relevel(age, "Infant", "Toddler", "Preschool"),
census_region = fct_reorder(
  census_region,
  if_else(age == "Infant" & study_year == 2018, weekly_price, NA_real_),
  .fun = ~ max(., na.rm = TRUE),
  .desc = TRUE
  )
) |>
  ggplot(aes(study_year, weekly_price, color = census_region)) +
  geom_point(alpha = 0.6, size = 1.7) +
  geom_smooth(method = "loess", formula = y ~ x, se = TRUE, linewidth = 0.8) +
  facet_wrap(~ age, nrow = 1) +
  scale_x_continuous(breaks = seq(2008, 2018, 2), limits = c(2008, 2018)) +
  scale_y_continuous(breaks = seq(100, 500, 50),
  limits = c(100, 520),
  labels = scales::label_dollar()) +
  scale_color_manual(values = pal10, name = "California Region") +
  labs(
  title = "Weekly Median Price for Center-Based Childcare ($)",
  x = "Study Year",
  y = "Weekly Median Price ($)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
  legend.position = "right",
  aspect.ratio = 1,
  panel.grid.minor = element_blank()
)
```

-   I can modify my colors to be accessible to anyone's eyes

```{r}
# Lab 2 Challenge Question 1
#| label: dvs-2-ex-2
#| label: medium-option-colors
#| echo: true
#| message: false
#| warning: false

p_base <- ggplot(
  plot_df,
  aes(x = species, y = weight, fill = sex)
) +
  geom_boxplot(
    outlier.shape = NA,
    position = position_dodge2(width = 0.8, preserve = "single")
  ) +
  geom_jitter(
    aes(color = sex),
    alpha = 0.35,
    position = position_jitterdodge(
      jitter.width = 0.15,
      jitter.height = 0,
      dodge.width = 0.8
    )
  ) +
  labs(
    title = "Rodent Weight by Species and Sex",
    x = "Species",
    y = "Weight (g)",
    fill = "Sex",
    color = "Sex"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

sex_cols <- c(F = "steelblue", M = "orange3")
p_manual <- p_base +
  scale_fill_manual(values = sex_cols) +
  scale_color_manual(values = sex_cols, guide = "none")
p_manual

p_pkg <- p_base +
  # Source: https://ggplot2.tidyverse.org/reference/scale_viridis.html
  scale_fill_viridis_d(option = "C") +
  scale_color_viridis_d(option = "C", guide = "none")
p_pkg
```

-   I can modify my plot titles to clearly communicate the data context

```{r}
# Lab 4 Question 8
#| label: dvs-2-ex-3
#| label: scatterplot-median-income-vs-childcare-cost
ca_childcare |>
  filter(!is.na(mhi_2018), !is.na(mc_infant)) |>
  mutate(
    census_region = fct_reorder(census_region, mc_infant, .fun = median, .desc = TRUE)
  ) |>
  ggplot(aes(x = mhi_2018, y = mc_infant, color = census_region)) +
  geom_point(alpha = 0.6, size = 1.5) +
  geom_smooth(aes(group = 1), method = "lm", se = FALSE) +
  scale_x_continuous(labels = scales::dollar_format(accuracy = 1)) +
  scale_y_continuous(labels = scales::dollar_format(accuracy = 1)) +
  labs(
    x = "Median household income (2018 dollars)",
    y = "Weekly price: center-based infant care ($)",
    color = "California Region",
    title = "Median Household Income vs. Infant Center-Based Childcare Prices (CA)"
  ) +
  theme_minimal(base_size = 12) +
  theme(aspect.ratio = 1)
```

-   I can modify the text in my plot to be more readable

```{r}
#| label: dvs-2-ex-4
# Challenge 2 Embedding Legend in Plot Title
#| echo: true
#| label: html-subtitle
#| eval: false

ggplot(data = penguins, 
       mapping = aes(x = bill_length_mm, y = species, color = island)
       ) +
  geom_boxplot() +
  scale_color_manual(values = untitled_red) +
  labs(x = "Bill Length (mm)", 
       y = "", 
       title = "Length of Different Penguin Species' Bills", 
       subtitle = "Separated by <span style = 'color:#c8251d;'>Biscoe</span>, <span style = 'color:#a11b26;'>Dream</span> and <span style = 'color:#ef6552;'>Torgenson</span> Islands") +
  theme(
    legend.position = "none", 
    plot.subtitle = element_markdown()
    ) +
  theme_bw()
```

-   I can reorder my legend to align with the colors in my plot

```{r}
#| label: dvs-2-ex-5
# Challenge 2 Question 2
# The legend order is F then M, which matches the order of colors in sex_cols.
plot_df <- surveys %>%
  filter(
    !is.na(species), species != "",
    !is.na(weight),  weight > 0,
    sex %in% c("F", "M")
  ) %>%
  mutate(
    species = fct_drop(as.factor(species)),
    sex     = factor(sex, levels = c("F", "M"))
  )

sex_cols <- c(F = "steelblue", M = "orange3")
p_manual <- p_base +
  scale_fill_manual(values = sex_cols) +
  scale_color_manual(values = sex_cols, guide = "none")

```

**DVS-3: I show creativity in my visualizations**

-   I can use non-standard colors (Example 1)

```{r}
# Challenge 2 Question 2
#| label: dvs-3-1-ex-1
sex_cols <- c(F = "steelblue", M = "orange3")
p_manual <- p_base +
  scale_fill_manual(values = sex_cols) +
  scale_color_manual(values = sex_cols, guide = "none")
p_manual
```

-   I can use non-standard colors (Example 2)

```{r}
#| label: dvs-3-1-ex-2
# Lab 10 Question 13
ci_plot_dat <- ci_dat %>%
  mutate(
    # https://dplyr.tidyverse.org/reference/row_number.html
    sim = row_number(),
    cover = factor(
      cover,
      levels = c(1, 0),
      labels = c("Covers true slope", "Misses true slope")
    )
  ) %>%
  filter(sim <= 100)

ggplot(ci_plot_dat,
       aes(x = sim, y = slope_est, ymin = ci_low, ymax = ci_high, color = cover)) +
  geom_errorbar() +
  geom_point(size = 0.8) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  scale_color_manual(
    values = c(
      "Covers true slope" = "#0072B2",  # colorblind-friendly blue
      "Misses true slope" = "#D55E00"   # colorblind-friendly orange
    )
  ) +
  labs(
    x = "Simulation number",
    y = "Slope estimate with 95% CI",
    color = "Interval",
    title = "Confidence Interval Coverage for the Slope (First 100 Sims)"
  ) +
  theme_minimal()
```

-   I can use annotations (e.g., `geom_text()`)

```{r}
#| label: dvs-3-2
# Challenge 3 Question 2
# Modified to add geom_text.
ggplot(teacher_evals_compare, aes(x = sen_level, fill = SET_level)) +
  geom_bar(stat = "count", position = "fill", width = 0.9) +
  geom_text(
    stat = "count",
    # https://www.rdocumentation.org/packages/ggplot2/versions/2.1.0/topics/position_fill
    position = position_fill(vjust = 0.5),
    aes(
      label = after_stat(
        label_percent(accuracy = 1)(prop)
      )
    ),
    color = "white",
    size = 3.5
  ) +
  scale_y_continuous(labels = percent_format(accuracy = 1), expand = c(0, 0)) +
  scale_fill_manual(
    name = "Evaluation Rating",
    values = c(excellent = "#B39DDB", standard = "#B48A54")
  ) +
  labs(
    title = "Evaluation of Teachers' Use of Activities",
    x = "Years of Experience", y = NULL
  ) +
  theme_minimal(base_size = 16) +
  theme(legend.position = "top", panel.grid.minor = element_blank())

```

-   I can choose creative geometries (e.g., `geom_segment()`, `geom_ribbon)()`)

```{r}
#| label: dvs-3-3
# Lab 10 Question 13
ci_plot_dat <- ci_dat %>%
  mutate(
    # https://dplyr.tidyverse.org/reference/row_number.html
    sim = row_number(),
    cover = factor(
      cover,
      levels = c(1, 0),
      labels = c("Covers true slope", "Misses true slope")
    )
  ) %>%
  filter(sim <= 100)

ggplot(ci_plot_dat,
       aes(x = sim, y = slope_est, ymin = ci_low, ymax = ci_high, color = cover)) +
  # Modified: Added geom_segment so each confidence interval drawn as a vertical segment
  geom_segment(aes(xend = sim, y = ci_low, yend = ci_high)) +
  geom_point(size = 0.8) +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  scale_color_manual(
    values = c(
      "Covers true slope" = "#0072B2",  # colorblind-friendly blue
      "Misses true slope" = "#D55E00"   # colorblind-friendly orange
    )
  ) +
  labs(
    x = "Simulation number",
    y = "Slope estimate with 95% CI",
    color = "Interval",
    title = "Confidence Interval Coverage for the Slope (First 100 Sims)"
  ) +
  theme_minimal()
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example using `summarize()`

```{r}
# Lab 3 Question 6
#| label: dvs-4-summarize
teacher_evals_clean |>
  summarise(
    unique_instructors = n_distinct(teacher_id),
    unique_courses     = n_distinct(course_id)
  )
```

-   Example using `across()`

```{r}
#| label: dvs-4-across
# Lab 3 Question 3
teacher_evals |>
  summarise(across(
    c(no_participants, resp_share, SET_score_avg, percent_failed_cur, seniority),
    list(min = ~min(.x, na.rm = TRUE),
         median = ~median(.x, na.rm = TRUE),
         mean = ~mean(.x, na.rm = TRUE),
         max = ~max(.x, na.rm = TRUE))
  ))
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r}
#| label: dvs-5-1
# Lab 4 Challenge Summary Table Trend Plot
plot_data <- ca_childcare |>
  group_by(census_region, study_year) |>
  summarise(
    center = median(mc_infant, na.rm = TRUE),
    family = median(mfcc_infant, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_longer(c(center, family), names_to = "setting", values_to = "weekly_price") |>
  mutate(
    setting = recode(setting, center = "Center-based", family = "Family (in-home)"),
    order_val = if_else(study_year == 2018 & setting == "Center-based", weekly_price, NA_real_),
    census_region = forcats::fct_reorder(census_region, order_val, .fun = ~ max(., na.rm = TRUE), .desc = TRUE)
  )

```

-   Example 2

```{r}
# Lab 4 Question 5
#| label: dvs-5-2
income_region_2008_2018 <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(census_region, study_year) |>
  summarise(median_mhi_2018 = median(mhi_2018, na.rm = TRUE), .groups = "drop") |>
  pivot_wider(
    names_from = study_year,
    values_from = median_mhi_2018
  ) |>
  rename(region = census_region) |>
  arrange(desc(`2018`))
```

**DVS-6: I can create tables which make my summaries clear to the reader.**

-   I can modify my column names to clearly communicate the data context

```{r}
# Lab 4 Challenge Summary Table
#| label: dvs-6-ex-1
# Modified to have descriptive names
pivot_wider(names_from = study_year, values_from = c(center, family), names_sep = "_") |>
  mutate(
    region = census_region,
    `Median center price, 2008 (USD/week)`  = center_2008,
    `Median family price, 2008 (USD/week)`  = family_2008,
    `Median center price, 2018 (USD/week)`  = center_2018,
    `Median family price, 2018 (USD/week)`  = family_2018,
    `Gap in 2018 (center − family, USD/week)` = center_2018 - family_2018
  )
```

-   I can modify the text in my table to be more readable (e.g., bold face for column headers)

```{r}
# Lab 9 Question 3
#| label: dvs-6-ex-2
surveys |>
  map_chr(~ class(.x)[1]) |>
  enframe(name = "Variable", value = "Data Type") |>
  arrange(`Data Type`, Variable) |>
  gt() |>
  cols_label(
    Variable    = "Variable",
    `Data Type` = "Data type"
  ) |>
  tab_header(
    title = "Data types of variables in `surveys`"
  ) |>
  tab_style(
  # https://gt.rstudio.com/reference/cell_text.html
    style = cell_text(weight = "bold"),
  # https://gt.rstudio.com/reference/cells_column_labels.html
    locations = cells_column_labels()
  )
```

-   I can arrange my table to have an intuitive ordering

```{r}
# Lab 9 Question 7
#| label: dvs-6-ex-3
fish %>%
  map_int(~ sum(is.na(.x))) %>%
  enframe(name = "Variable", value = "Missing_N") %>%
  mutate(Missing_Pct = Missing_N / nrow(fish)) %>%
  arrange(desc(Missing_N), Variable) %>%
  gt() %>%
  cols_label(
# https://www.rdocumentation.org/packages/gt/versions/0.8.0/topics/md
    Variable    = md("**Variable**"),
    Missing_N   = md("**Missing (N)**"),
    Missing_Pct = md("**Missing (%)**")
  ) %>%
  fmt_percent(columns = Missing_Pct, decimals = 1) %>%
# https://gt.rstudio.com/reference/tab_header.html
  tab_header(title = md("Missing Values by Variable — `fish`")) %>%
# https://gt.rstudio.com/reference/opt_row_striping.html
  opt_row_striping()
```

**DVS-7: I show creativity in my tables.**

-   I can use non-default colors

```{r}
#| label: dvs-7-ex-1
# Lab 9 Question 8
fish %>%
  map_int(~ sum(is.na(.x))) %>%
  enframe(name = "variable", value = "missing_n") %>%
  arrange(desc(missing_n), variable) %>%
  gt() %>%
  cols_label(
    variable  = md("**Measurement Variable**"),
    missing_n = md("**Missing Values**")
  ) %>%
# https://www.rdocumentation.org/packages/gt/versions/1.1.0/topics/cols_align
  cols_align(align = "center", columns = everything()) %>%
  data_color(
    columns = missing_n,
    colors = function(x) {
      col_numeric(
        palette = viridis(5, option = "C"),
        domain  = c(0, max(x, na.rm = TRUE))
      )(x)
    }
  ) %>%
# https://gt.rstudio.com/reference/tab_header.html
  tab_header(
    title = md("Number of Missing Values for Fish Measurements"),
    subtitle = md("Data collected from 1989 to 2006 on the Blackfoot River in Montana")
  ) %>%
# https://gt.rstudio.com/reference/opt_row_striping.html
  opt_row_striping()
```

-   I can modify the layout of my table to be more readable (e.g., `pivot_longer()` or `pivot_wider()`)

```{r}
# Lab 9 Question 6
# The important part is using pivot_longer() to turn the table into long layout with variable
# and level
#| label: dvs-7-ex-2
evals %>%
  distinct(teacher_id, .keep_all = TRUE) %>%
  mutate(
    sen_level = case_when(
      seniority <= 4 ~ "Junior",
      seniority <= 8 ~ "Senior",
      seniority >  8 ~ "Very Senior",
      TRUE ~ NA_character_
    ),
    academic_degree = case_when(
      str_to_lower(academic_degree) %in% c("phd","doctorate","doctoral") ~ "Doctorate",
      str_to_lower(academic_degree) %in% c("masters","master","ma","ms")  ~ "Masters",
      str_detect(str_to_lower(academic_degree), "no")            ~ "No Degree",
      str_detect(str_to_lower(academic_degree), "tenur")         ~ "Tenured Professor",
      TRUE ~ academic_degree
    ),
    sex = str_to_title(sex)
  ) %>%
  select(`Academic Degree` = academic_degree, `Seniority` = sen_level, `Sex` = sex) %>%
  # pivot_longer used here
  pivot_longer(everything(), names_to = "variable", values_to = "level") %>%
  filter(!is.na(level)) %>%
  filter(!(variable == "Seniority" & level == "Very Senior")) %>%
  group_by(variable, level) %>%
  summarise(n = n(), .groups = "drop_last") %>%
  mutate(prop = n / sum(n)) %>%
  ungroup() %>%
  mutate(
    variable = fct_relevel(variable, "Seniority","Sex","Academic Degree"),
    level_order = case_when(
# https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/match
      variable == "Academic Degree" ~ match(level, c("No Degree","Masters","Doctorate","Tenured Professor")),
      variable == "Seniority"       ~ match(level, c("Junior","Senior")),
      variable == "Sex"             ~ match(level, c("Female","Male")),
      TRUE ~ NA_integer_
    )
  ) %>%
  arrange(variable, level_order, level) %>%
  select(-level_order) %>%
  gt(rowname_col = "level", groupname_col = "variable") %>%
# https://gt.rstudio.com/reference/tab_stubhead.html
  tab_stubhead(label = "Group") %>%
  cols_label(
    n    = "Count",
    prop = "%"
  ) %>%
# https://gt.rstudio.com/reference/tab_spanner.html
  tab_spanner(label = "Professors", columns = c(n, prop)) %>%
  fmt_percent(columns = prop, decimals = 2) %>%
# https://gt.rstudio.com/reference/fmt_number.html
  fmt_number(columns = n, decimals = 0) %>%
# https://gt.rstudio.com/reference/tab_header.html
  tab_header(
# https://www.rdocumentation.org/packages/gt/versions/0.8.0/topics/md
    title = md("Demographics of Professors"),
    subtitle = md("Student Evaluations at the University of Poland, Warsaw in 2020")
  ) %>%
# https://gt.rstudio.com/reference/opt_row_striping.html
  opt_row_striping()
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call with multiple inputs (rather than multiple function calls)

```{r}
# Lab 3 Question 3
#| label: pe-1-one-call
# Used one function call to tibble() using multiple inputs instead of many calls to tibble().
tibble(
  rows        = nrow(teacher_evals),
  cols        = ncol(teacher_evals),
  instructors = n_distinct(teacher_evals$teacher_id),
  courses     = n_distinct(teacher_evals$course_id),
  questions   = n_distinct(teacher_evals$question_no)
)
```

-   using `across()`

```{r}
# Lab 3 Question 3
#| label: pe-1-across
teacher_evals |>
  # Used one summarise call with multiple inputs.
  summarise(across(
    c(no_participants, resp_share, SET_score_avg, percent_failed_cur, seniority),
    list(min = ~min(.x, na.rm = TRUE),
         median = ~median(.x, na.rm = TRUE),
         mean = ~mean(.x, na.rm = TRUE),
         max = ~max(.x, na.rm = TRUE))
  ))
```

-   using functions from the `map()` family

```{r}
#| label: pe-1-map-1
# Lab 9 Question 7
# man_int applies same function to every column of fish.
fish %>%
  map_int(~ sum(is.na(.x))) %>%
  enframe(name = "Variable", value = "Missing_N") %>%
  mutate(Missing_Pct = Missing_N / nrow(fish)) %>%
  arrange(desc(Missing_N), Variable) %>%
  gt() %>%
  cols_label(
# https://www.rdocumentation.org/packages/gt/versions/0.8.0/topics/md
    Variable    = md("**Variable**"),
    Missing_N   = md("**Missing (N)**"),
    Missing_Pct = md("**Missing (%)**")
  ) %>%
  fmt_percent(columns = Missing_Pct, decimals = 1) %>%
# https://gt.rstudio.com/reference/tab_header.html
  tab_header(title = md("Missing Values by Variable — `fish`")) %>%
# https://gt.rstudio.com/reference/opt_row_striping.html
  opt_row_striping()
```

**PE-2: I can write functions to reduce repetition in my code.**

-   Example 1: Function that operates on vectors

```{r}
#| label: pe-2-1
# Lab 10 Question 1
randomBabies <- function(n_babies){
  # https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/sample
  assignment <- sample.int(n_babies, size = n_babies, replace = FALSE)
  sum(assignment == 1:n_babies)
}
```

-   Example 2: Function that operates on data frames

```{r}
#| label: pe-2-2
# Lab 8 Question 1
#| label: df-rescale-function
rescale_01 <- function(x) {
  if (!is.numeric(x)) {
    stop("`x` must be numeric.")
  }
  if (length(x) <= 1) {
    stop("`x` must have length greater than 1.")
  }
  r <- range(x, na.rm = TRUE)
  (x - r[1]) / (r[2] - r[1])
}

rescale_column <- function(data, cols) {
  mutate(data, across({{ cols }}, rescale_01))
}
```

-   Example 3: Function that operates on vectors *or* data frames

```{r}
#| label: pe-2-3
# Lab 8 Question 1
#| label: pivot-table-function
pivot_table <- function(data, row, col) {
  data |>
    count({{ row }}, {{ col }}, name = "n") |>
    pivot_wider(
      names_from  = {{ col }},
      values_from = n,
      values_fill = 0
    ) |>
    janitor::adorn_totals(where = c("row", "col"))
}
```

**PE-3: I can use iteration to reduce repetition in my code.**

-   using `across()`

```{r}
#| label: pe-3-across
# Lab 4 Challenge Summary Table
summary_table <- ca_childcare |>
  filter(study_year %in% c(2008, 2018)) |>
  group_by(census_region, study_year) |>
  summarise(
    center = median(mc_infant, na.rm = TRUE),
    family = median(mfcc_infant, na.rm = TRUE),
    .groups = "drop"
  ) |>
  pivot_wider(names_from = study_year, values_from = c(center, family), names_sep = "_") |>
  mutate(
    region = census_region,
    `Median center price, 2008 (USD/week)`  = center_2008,
    `Median family price, 2008 (USD/week)`  = family_2008,
    `Median center price, 2018 (USD/week)`  = center_2018,
    `Median family price, 2018 (USD/week)`  = family_2018,
    `Gap in 2018 (center − family, USD/week)` = center_2018 - family_2018
  ) |>
  select(region, `Center 2008`, `Family 2008`, `Center 2018`, `Family 2018`, `Gap 2018 (Center−Family)`) |>
  arrange(desc(`Center 2018`)) |>
  mutate(across(where(is.numeric), ~ round(.)))
knitr::kable(summary_table, caption = "Median weekly infant prices (USD) by region and setting, 2008 vs 2018")
```

-   using a `map()` function with **one** input (e.g., `map()`, `map_chr()`, `map_dbl()`, etc.)

```{r}
#| label: pe-3-map-1
# Lab 9 Question 4
#| label: map-to-mutate-columns
cols_to_factor <- c("course_id", "weekday", "academic_degree", "time_of_day", "sex")
evals_factored <- bind_cols(
  map_at(evals, cols_to_factor, as.factor)
)
```

-   using a `map()` function with **one** input

```{r}
#| label: pe-3-map-2
# Lab 9 Quesion 2
#| label: map-data-types-of-surveys
surveys |>
  map_chr(~ class(.x)[1]) |>
  enframe(name = "Variable", value = "Data Type") |>
  kable(caption = "Data types of variables in `surveys`")
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   I can use functions which are not superseded or deprecated

```{r}
# Lab 10 Question 3
#| label: pe-4-1
viz_data <- enframe(results, name = NULL, value = "n_correct") %>%
  count(n_correct, name = "count") %>%
  mutate(prop = count / sum(count))

ggplot(viz_data, aes(x = factor(n_correct), y = prop)) +
  geom_col() +
  scale_y_continuous(labels = label_percent(accuracy = 1)) +
  labs(
    x = "Number of babies correctly matched",
    y = "Proportion of simulations",
    title = "Distribution of correctly matched babies (n = 4, 10,000 sims)"
  )

```

-   I can connect a data wrangling pipeline into a `ggplot()`

```{r}
# Lab 4 Question 7
#| label: pe-4-2
ca_childcare |>
  select(study_year, census_region, mc_infant, mc_toddler, mc_preschool) |>
  pivot_longer(
  cols = starts_with("mc_"),
  names_to = "age",
  names_prefix = "mc_",
  values_to = "weekly_price",
  values_drop_na = TRUE
  ) |>
  mutate(
  age = fct_recode(factor(age),
  "Infant" = "infant",
  "Toddler" = "toddler",
  "Preschool" = "preschool"),
  age = fct_relevel(age, "Infant", "Toddler", "Preschool"),
census_region = fct_reorder(
  census_region,
  if_else(age == "Infant" & study_year == 2018, weekly_price, NA_real_),
  .fun = ~ max(., na.rm = TRUE),
  .desc = TRUE
  )
) |>
  ggplot(aes(study_year, weekly_price, color = census_region)) +
  geom_point(alpha = 0.6, size = 1.7) +
  geom_smooth(method = "loess", formula = y ~ x, se = TRUE, linewidth = 0.8) +
  facet_wrap(~ age, nrow = 1) +
  scale_x_continuous(breaks = seq(2008, 2018, 2), limits = c(2008, 2018)) +
  scale_y_continuous(breaks = seq(100, 500, 50),
  limits = c(100, 520),
  labels = scales::label_dollar()) +
  scale_color_manual(values = pal10, name = "California Region") +
  labs(
  title = "Weekly Median Price for Center-Based Childcare ($)",
  x = "Study Year",
  y = "Weekly Median Price ($)"
  ) +
  theme_minimal(base_size = 14) +
  theme(
  legend.position = "right",
  aspect.ratio = 1,
  panel.grid.minor = element_blank()
)
```

## Data Simulation & Statistical Models

**DSSM-1: I can simulate data from a *variety* of probability models.**

-   Example 1

```{r}
#| label: dsm-1-1
# Lab 10 Question 3
#| label: data-generation

# define slope and intercept parameters
intercept = 2
slope = 1

# generate x vector
x <- runif(n = 100, min = 0, max = 1)

# generate noise `ep` vector
ep <- rnorm(n = 100, mean = 0, sd = 1)

# generate outcome from population model
y = intercept + x*slope + ep

# create an "observed data" dataframe with only the x and y vectors
observed_data <- tibble(x = x, y = y)
```

-   Example 2

```{r}
#| label: dsm-1-2
# Lab 10 Question 1
randomBabies <- function(n_babies){
  # https://www.rdocumentation.org/packages/base/versions/3.6.2/topics/sample
  assignment <- sample.int(n_babies, size = n_babies, replace = FALSE)
  sum(assignment == 1:n_babies)
}
set.seed(123)
results <- map_int(
  .x = 1:10000,
  .f = ~ randomBabies(4)
)
```

**DSSM-2: I can conduct common statistical analyses in R.**

-   Example 1

```{r}
# Lab 2 Question 17
#| label: dsm-2-1
#| label: q17-anova-fit
#| echo: true
rodents <- surveys %>%
  filter(
    taxa == "Rodent",
    !is.na(species), species != "",
    !is.na(weight), weight > 0
  ) %>%
  dplyr::mutate(species = forcats::fct_drop(as.factor(species)))

rodents %>% count(species, sort = TRUE)

species_mod <- aov(weight ~ species, data = rodents)

summary(species_mod)
```

-   Example 2

```{r}
# Lab 10 Question 5 and 6
#| label: dsm-2-2
fit_lm <- lm(y ~ x, data = observed_data)

summary(fit_lm)

slope_ci <- tidy(fit_lm, conf.int = TRUE, conf.level = 0.95) %>%
  filter(term == "x")

slope_ci
```

## Revising My Thinking

<!-- How did you revise your thinking throughout the course? How did you revise your thinking on the code examples you have provided in your portfolio? -->

<!-- For the revisions included in your Portfolio, to help me understand the nature of your revisions, please denote somehow the feedback I provided you (e.g., boldface, italics, colored text) before your revisions. -->

I changed my Lab 5 as I realized from the learning requirements that I could have used a right_join() instead of a left_join(). This was realized after understanding that data is very manipulable and that you can take many path to arrive at the same outcome. I made the change for wd-5 to reflect this learning moment.

Another way I would revise my thinking would be to use your feedback, along with peer feedback, to improve the current and future assignments. One example was how I was repeatedly using the dlpyr:: package on every function call when I had already imported it. I was doing this because I got an error the first time we learned it so I thought this was a must. But after seeing peer assignments and your constant feedback, I've removed the bad habit and began to trust the libraries.

I've also really tried pushing for efficient code by reducing the amount of intermediary object to make the code clean and efficient.

One notable demonstration of improvement was documenting my code. I wasn't consistent with this, but in Lab 5 I realized it would be important to include comments explaining my thought process of why I did certain things.

In general, I've used the feedback to resubmit almost all of my assignments and also make improvements in the portfolio to become a more consistent in producing efficient R code. I know I repeat mistakes but I those are the ones that stick with me once I finally understand and break a bad habit.

## Extending My Thinking

<!-- How did you extended your thinking throughout the course? How did you extend your thinking on the code examples you have provided in your portfolio? -->

The feedback provided was very helpful as it challenged me to learn new ways of accomplishing the task. Specifically for Lab 4, you provided the feedback of looking for a way to reordering through functions instead of my hand by using fct_reorder(). I realized that for most things you think of, there's probably a function for the intended purpose.

Another way I extended my thinking was connecting what you taught about using shapes instead of just colors for color blind people to make work more accessible. I looked into color blind palette and found packages which are suitable for most color blind folks through the virdis package. The reason this was important was because I learned about WCAG from my UI class and realized I should apply the same to programming in R.

<https://ggplot2.tidyverse.org/reference/scale_viridis.html>

<https://www.w3.org/WAI/standards-guidelines/wcag/>

I also extended my thinking by looking at different ways of using piping instead of just "\|\>" but also "%\>%" as I remember in class this being mentioned. I learned that there are different ways because packages were introduced in the language based on what popular third party packages were doing to constantly improve the R language, therefore making it continuously evolving. The nature of this is to always look for efficiency and better ways of accomplishing goals.

I think the biggest way I extended my thinking was in the constructions of my plots. I did this in Lab 10 Question 13, where we were only given instructions to create a coverage rate plot. After constructing the "coverage plot", I realized that the plot made it difficult to actually showcase "coverage" which I thought would be best done by a bar plot or pie chart. This is because all the "lines" representing simulations should be collapsed to distinguish them which I created in addition to what was expected.

## Peer Support & Collaboration

<!-- Include an image or a description of feedback you gave that you are proud of (either in a peer review or in Discord). -->

<!-- Include a description of how you grew as a collaborator through the weekly pair programming activities.   -->

I didn't know pair programming would be so helpful but I was amazed by how much it made me realize about my thought process. By just typing and listening to someone else, I was able to think from another person's perspective and I believe this helps with trying to think differently when I work by myself later. This was really helpful especially for the time murder investigation peer activity because these were libraries I had never used before and the lab itself was a really good challenge. By working with someone else, I got to see my shortcomings when I wasn't able to thoughtfully describe what I wanted the programmer to do. This made me slow down my thinking and become better at describing my thought process.

I provided feedback on all of the weekly peer reviews and I think I grew a lot in this category. I grew a lot because of the feedback I received from the TA and Professor in terms of how I provide feedback. This gave me an opportunity to be more specific for how I can look for efficient improvements. I am particularly proud of my Lab 5 feedback because I looked into how they could reduce the lines of code by taking advantage of inner_join() even if the code they provided was correct. This in turn helps me look for more improvement in my own code. Receiving peer review feedback was also very helpful as it pointed out mistakes I was making but not even realizing. One of things I received feedback early on for was indenting and using next lines to make the code more readable. I started doing this and have received compliments on the readability of my code.

Here is my peer review for Lab 5:

"Hi!

This lab was put together real well. I really enjoyed the thoughtful descriptions for each part of constructing the investigation. It made it easy to piece together your thought process and why you did certain things. I also really liked how you reduced intermediary objects by keeping strong piping.

One thing I would recommend is using pull(description) instead of select(description) as well as pull(transcript). select() is usually used for when you need a data frame potentially for renaming or reorganizing. If you just want to grab a simple single vector, pull() is much better alternative.

Another thing I would recommend is instead of doing multiple left_joins(), you can save same object/processes that you did in previous steps to combine with a inner_join() to create shorter and more efficient code. This is especially helpful near the end when you know the final suspect's physical description and the concert.

Overall this was great work and I also learned from reading your code!"
